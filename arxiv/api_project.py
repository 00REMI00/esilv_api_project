# -*- coding: utf-8 -*-
"""API_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GK4brXuRc2AR7_-bVBDysNuqlL0SFqpE
"""

!pip install Flask
!pip install xml.etree

import requests
import datetime
from flask import Flask, jsonify, Response
import json
from xml.etree import ElementTree #pour lire les données de l'api arxiv car je n'arrive pas à convertir les données en json

app = Flask(__name__)
app.config["DEBUG"] = True

@app.route('/', methods=['GET'])
def home():
   return "<h1>Projet API</h1><p>Cette page est la présentation de mon API</p>"

url = 'https://export.arxiv.org/api/query'

def arxiv_data(search_query,nb_results=5):
  params = {
      'search_query': search_query,
      'max_results': nb_results
  }
  answer = requests.get(url,params=params)
  if answer.status_code == 200:
    return ElementTree.fromstring(answer.content) #returns feed (we can find every information inside of the feed)
  else:
    return []

arxiv_data('cat:AI')

def get_articles():
  articles = []
  query = input("Give me a key word of what articles you are searching : ")
  data = arxiv_data(f"all:{query}") #fetch 5 articles from the specified category
  path = '{http://www.w3.org/2005/Atom}'
  for entry in data.findall(path+'entry'): #feed contains child <entry> elements with each <entry> representing an article
    title = entry.find(path+'title').text
    summary = entry.find(path+'summary').text
    author = entry.find(path+'author').find(path+'name').text
    date = entry.find(path+'published').text[0:10]
    link = entry.find(path+'id').text
    id = link[21:]
    urlpdf = f"http://arxiv.org/pdf/{id}"

    articles.append([title, date, id, link, author, urlpdf, summary])

  for article in articles:
    article[1] = datetime.datetime.strptime(article[1], '%Y-%m-%d')
  articles.sort(key=lambda x: x[1], reverse = True)
  return articles

articles = get_articles()
print(type(articles))

@app.route('/get_data',methods=['GET'])
def get_data():
  query = input("Give me a key word of what articles you are searching : ")
  data = arxiv_data(f"all:{query}") #fetch 5 articles from the specified category
  path = '{http://www.w3.org/2005/Atom}'
  list_of_articles = []
  for entry in data.findall(path+'entry'):
    title= entry.find(path+'title').text
    link = entry.find(path+'id').text
    list_of_articles.extend({'Title' : f'{title}','Link': f'{link}'})
  return jsonify(list_of_articles)

@app.route('/articles',methods=['GET'])
def articles():
  query = input("Give me a key word of what articles you are searching : ")
  data = arxiv_data(f"all:{query}")
  path = '{http://www.w3.org/2005/Atom}'
  articles = []
  for entry in data.findall(path+'entry'):
    title= entry.find(path+'title').text
    link = entry.find(path+'id').text
    author = entry.find(path+'author').find(path+'name').text
    date = entry.find(path+'published').text[0:10]
    id = link[21:]
    urlpdf = f"http://arxiv.org/pdf/{id}"
    articles.append({'Title':f'{title}','Date': f'{date}','Id': f'{id}','Link': f'{link}','Author': f'{author}','Pdf': f'{urlpdf}'})
  return jsonify(articles)

@app.route('/article/<int:number>',methods=['GET'])
def specified_article(number):
  articles = get_articles()
  if (number >=1 and number <= len(articles)):
    specified = articles[number-1]
    return jsonify(specified)
  else:
    error = input(f"Error : number out of range, give a number between 1 and {len(articles)} :")
    return specified_article(error)
specified_article(2)